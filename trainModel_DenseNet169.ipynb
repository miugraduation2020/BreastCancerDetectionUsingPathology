{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tV019gBL8J4t",
    "outputId": "11feae0f-553b-4086-b9c3-54dc6fa24672"
   },
   "outputs": [],
   "source": [
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D1LQphux8J4x",
    "outputId": "f0f23e43-b52f-4e0a-c98d-adbfce9407a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1882 images belonging to 4 classes.\n",
      "Found 40 images belonging to 4 classes.\n",
      "Found 40 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "train_datagen = ImageDataGenerator() \n",
    "valid_datagen = ImageDataGenerator() \n",
    "test_datagen = ImageDataGenerator() \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=r\"D:\\\\Graduation Project\\\\Dataset\\\\ICIAR2018_BACH_Challenge\\\\Dataset\\\\AugPhotos\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory=r\"D:\\\\Graduation Project\\\\Dataset\\\\ICIAR2018_BACH_Challenge\\\\Dataset\\\\Validation\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=r\"D:\\\\Graduation Project\\\\Dataset\\\\ICIAR2018_BACH_Challenge\\\\Dataset\\\\Test\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Q6VzxVS8J40",
    "outputId": "cea9e807-c3d5-4ff1-c109-6b96de062cb8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "img_rows, img_cols, img_channel = 224, 224, 3\n",
    "base_model = tf.keras.applications.DenseNet169(\n",
    "    include_top=False, weights='imagenet', input_tensor=None,\n",
    "    input_shape=(img_rows, img_cols, img_channel), pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "a1fPWtbEFEy0"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbE-uHbp8J41",
    "outputId": "9e7827d5-7d6e-484f-9660-37d497813124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_relu (Activatio (None, 14, 14, 1024) 0           conv4_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 14, 14, 128)  131072      conv4_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_concat (Concatena (None, 14, 14, 1056) 0           conv4_block24_concat[0][0]       \n",
      "                                                                 conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_bn (BatchNormal (None, 14, 14, 1056) 4224        conv4_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_relu (Activatio (None, 14, 14, 1056) 0           conv4_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 14, 14, 128)  135168      conv4_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_concat (Concatena (None, 14, 14, 1088) 0           conv4_block25_concat[0][0]       \n",
      "                                                                 conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_bn (BatchNormal (None, 14, 14, 1088) 4352        conv4_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_relu (Activatio (None, 14, 14, 1088) 0           conv4_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 14, 14, 128)  139264      conv4_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_concat (Concatena (None, 14, 14, 1120) 0           conv4_block26_concat[0][0]       \n",
      "                                                                 conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_bn (BatchNormal (None, 14, 14, 1120) 4480        conv4_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_relu (Activatio (None, 14, 14, 1120) 0           conv4_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 14, 14, 128)  143360      conv4_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_concat (Concatena (None, 14, 14, 1152) 0           conv4_block27_concat[0][0]       \n",
      "                                                                 conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_bn (BatchNormal (None, 14, 14, 1152) 4608        conv4_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_relu (Activatio (None, 14, 14, 1152) 0           conv4_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 14, 14, 128)  147456      conv4_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_concat (Concatena (None, 14, 14, 1184) 0           conv4_block28_concat[0][0]       \n",
      "                                                                 conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_bn (BatchNormal (None, 14, 14, 1184) 4736        conv4_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_relu (Activatio (None, 14, 14, 1184) 0           conv4_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 14, 14, 128)  151552      conv4_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_concat (Concatena (None, 14, 14, 1216) 0           conv4_block29_concat[0][0]       \n",
      "                                                                 conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_bn (BatchNormal (None, 14, 14, 1216) 4864        conv4_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_relu (Activatio (None, 14, 14, 1216) 0           conv4_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 14, 14, 128)  155648      conv4_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_concat (Concatena (None, 14, 14, 1248) 0           conv4_block30_concat[0][0]       \n",
      "                                                                 conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_bn (BatchNormal (None, 14, 14, 1248) 4992        conv4_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_relu (Activatio (None, 14, 14, 1248) 0           conv4_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 14, 14, 128)  159744      conv4_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_concat (Concatena (None, 14, 14, 1280) 0           conv4_block31_concat[0][0]       \n",
      "                                                                 conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1280) 5120        conv4_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1280) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 640)  819200      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 640)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 640)    2560        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 640)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 672)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 672)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 704)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 704)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 736)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 736)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 768)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 768)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 800)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 800)    3200        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 800)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    102400      conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 832)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 832)    3328        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 832)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    106496      conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 864)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 864)    3456        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 864)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    110592      conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 896)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 896)    3584        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 896)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    114688      conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 928)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 960)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 992)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 1024)   0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 1024)   4096        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 1024)   0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    131072      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 1056)   0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 1056)   4224        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 1056)   0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    135168      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 1088)   0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 1088)   4352        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 1088)   0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    139264      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 1120)   0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 1120)   4480        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 1120)   0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    143360      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1152)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_bn (BatchNormal (None, 7, 7, 1152)   4608        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_relu (Activatio (None, 7, 7, 1152)   0           conv5_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_conv (Conv2D)   (None, 7, 7, 128)    147456      conv5_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_concat (Concatena (None, 7, 7, 1184)   0           conv5_block16_concat[0][0]       \n",
      "                                                                 conv5_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_bn (BatchNormal (None, 7, 7, 1184)   4736        conv5_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_relu (Activatio (None, 7, 7, 1184)   0           conv5_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_conv (Conv2D)   (None, 7, 7, 128)    151552      conv5_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_concat (Concatena (None, 7, 7, 1216)   0           conv5_block17_concat[0][0]       \n",
      "                                                                 conv5_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_bn (BatchNormal (None, 7, 7, 1216)   4864        conv5_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_relu (Activatio (None, 7, 7, 1216)   0           conv5_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_conv (Conv2D)   (None, 7, 7, 128)    155648      conv5_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_concat (Concatena (None, 7, 7, 1248)   0           conv5_block18_concat[0][0]       \n",
      "                                                                 conv5_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_bn (BatchNormal (None, 7, 7, 1248)   4992        conv5_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_relu (Activatio (None, 7, 7, 1248)   0           conv5_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_conv (Conv2D)   (None, 7, 7, 128)    159744      conv5_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_concat (Concatena (None, 7, 7, 1280)   0           conv5_block19_concat[0][0]       \n",
      "                                                                 conv5_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_bn (BatchNormal (None, 7, 7, 1280)   5120        conv5_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_relu (Activatio (None, 7, 7, 1280)   0           conv5_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_conv (Conv2D)   (None, 7, 7, 128)    163840      conv5_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_concat (Concatena (None, 7, 7, 1312)   0           conv5_block20_concat[0][0]       \n",
      "                                                                 conv5_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_bn (BatchNormal (None, 7, 7, 1312)   5248        conv5_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_relu (Activatio (None, 7, 7, 1312)   0           conv5_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_conv (Conv2D)   (None, 7, 7, 128)    167936      conv5_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_concat (Concatena (None, 7, 7, 1344)   0           conv5_block21_concat[0][0]       \n",
      "                                                                 conv5_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_bn (BatchNormal (None, 7, 7, 1344)   5376        conv5_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_relu (Activatio (None, 7, 7, 1344)   0           conv5_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_conv (Conv2D)   (None, 7, 7, 128)    172032      conv5_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_concat (Concatena (None, 7, 7, 1376)   0           conv5_block22_concat[0][0]       \n",
      "                                                                 conv5_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_bn (BatchNormal (None, 7, 7, 1376)   5504        conv5_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_relu (Activatio (None, 7, 7, 1376)   0           conv5_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_conv (Conv2D)   (None, 7, 7, 128)    176128      conv5_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_concat (Concatena (None, 7, 7, 1408)   0           conv5_block23_concat[0][0]       \n",
      "                                                                 conv5_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_bn (BatchNormal (None, 7, 7, 1408)   5632        conv5_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_relu (Activatio (None, 7, 7, 1408)   0           conv5_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_conv (Conv2D)   (None, 7, 7, 128)    180224      conv5_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_concat (Concatena (None, 7, 7, 1440)   0           conv5_block24_concat[0][0]       \n",
      "                                                                 conv5_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_bn (BatchNormal (None, 7, 7, 1440)   5760        conv5_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_relu (Activatio (None, 7, 7, 1440)   0           conv5_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_conv (Conv2D)   (None, 7, 7, 128)    184320      conv5_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_concat (Concatena (None, 7, 7, 1472)   0           conv5_block25_concat[0][0]       \n",
      "                                                                 conv5_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_bn (BatchNormal (None, 7, 7, 1472)   5888        conv5_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_relu (Activatio (None, 7, 7, 1472)   0           conv5_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_conv (Conv2D)   (None, 7, 7, 128)    188416      conv5_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_concat (Concatena (None, 7, 7, 1504)   0           conv5_block26_concat[0][0]       \n",
      "                                                                 conv5_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_bn (BatchNormal (None, 7, 7, 1504)   6016        conv5_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_relu (Activatio (None, 7, 7, 1504)   0           conv5_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_conv (Conv2D)   (None, 7, 7, 128)    192512      conv5_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_concat (Concatena (None, 7, 7, 1536)   0           conv5_block27_concat[0][0]       \n",
      "                                                                 conv5_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_bn (BatchNormal (None, 7, 7, 1536)   6144        conv5_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_relu (Activatio (None, 7, 7, 1536)   0           conv5_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_conv (Conv2D)   (None, 7, 7, 128)    196608      conv5_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_concat (Concatena (None, 7, 7, 1568)   0           conv5_block28_concat[0][0]       \n",
      "                                                                 conv5_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_bn (BatchNormal (None, 7, 7, 1568)   6272        conv5_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_relu (Activatio (None, 7, 7, 1568)   0           conv5_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_conv (Conv2D)   (None, 7, 7, 128)    200704      conv5_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_concat (Concatena (None, 7, 7, 1600)   0           conv5_block29_concat[0][0]       \n",
      "                                                                 conv5_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_bn (BatchNormal (None, 7, 7, 1600)   6400        conv5_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_relu (Activatio (None, 7, 7, 1600)   0           conv5_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_conv (Conv2D)   (None, 7, 7, 128)    204800      conv5_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_concat (Concatena (None, 7, 7, 1632)   0           conv5_block30_concat[0][0]       \n",
      "                                                                 conv5_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_bn (BatchNormal (None, 7, 7, 1632)   6528        conv5_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_relu (Activatio (None, 7, 7, 1632)   0           conv5_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_conv (Conv2D)   (None, 7, 7, 128)    208896      conv5_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_concat (Concatena (None, 7, 7, 1664)   0           conv5_block31_concat[0][0]       \n",
      "                                                                 conv5_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1664)   6656        conv5_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1664)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 4)            20874500    relu[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 33,517,380\n",
      "Trainable params: 33,358,980\n",
      "Non-trainable params: 158,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "add_model.add(Dense(256, activation='relu'))\n",
    "add_model.add(Dropout(0.5))\n",
    "\n",
    "add_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1Ypkputj8J42"
   },
   "outputs": [],
   "source": [
    "\n",
    "def init_callbacks():\n",
    "  from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "  base_path = \"D:\\\\Graduation Project\\\\Dataset\\\\ICIAR2018_BACH_Challenge\\\\Dataset\\\\DenseNet169Weights\\\\\"\n",
    "\n",
    " \n",
    "  trained_models_path = base_path + 'model_weights'\n",
    "  model_names = trained_models_path + '.{epoch:04d}--{val_loss:.4f}--{val_accuracy:.4f}.h5'\n",
    "  model_checkpoint = ModelCheckpoint(model_names, monitor = 'val_accuracy', verbose=1,save_best_only=False,save_weights_only=True)\n",
    "\n",
    "  callbacks = [model_checkpoint]\n",
    "  return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PaX1kGKA8J44",
    "outputId": "d0e5edda-ac30-4aee-89c9-d1a2d342a185",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-31ca105ba1c7>:10: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.3976 - f1_m: 0.3533 - precision_m: 0.4311 - recall_m: 0.3012 \n",
      "Epoch 00001: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0001--0.4765--0.5000.h5\n",
      "58/58 [==============================] - 1830s 32s/step - loss: 0.6429 - accuracy: 0.3976 - f1_m: 0.3533 - precision_m: 0.4311 - recall_m: 0.3012 - val_loss: 0.4765 - val_accuracy: 0.5000 - val_f1_m: 0.4615 - val_precision_m: 0.6000 - val_recall_m: 0.3750\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3557 - accuracy: 0.6778 - f1_m: 0.6530 - precision_m: 0.7579 - recall_m: 0.5769 \n",
      "Epoch 00002: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0002--0.3394--0.7500.h5\n",
      "58/58 [==============================] - 1809s 31s/step - loss: 0.3557 - accuracy: 0.6778 - f1_m: 0.6530 - precision_m: 0.7579 - recall_m: 0.5769 - val_loss: 0.3394 - val_accuracy: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 0.8947 - val_recall_m: 0.5312\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2656 - accuracy: 0.7665 - f1_m: 0.7579 - precision_m: 0.8315 - recall_m: 0.6982 \n",
      "Epoch 00003: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0003--0.2746--0.7812.h5\n",
      "58/58 [==============================] - 2170s 37s/step - loss: 0.2656 - accuracy: 0.7665 - f1_m: 0.7579 - precision_m: 0.8315 - recall_m: 0.6982 - val_loss: 0.2746 - val_accuracy: 0.7812 - val_f1_m: 0.7931 - val_precision_m: 0.8846 - val_recall_m: 0.7188\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.8497 - f1_m: 0.8451 - precision_m: 0.9002 - recall_m: 0.7980 \n",
      "Epoch 00004: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0004--0.2791--0.6875.h5\n",
      "58/58 [==============================] - 1989s 34s/step - loss: 0.1927 - accuracy: 0.8497 - f1_m: 0.8451 - precision_m: 0.9002 - recall_m: 0.7980 - val_loss: 0.2791 - val_accuracy: 0.6875 - val_f1_m: 0.7368 - val_precision_m: 0.8400 - val_recall_m: 0.6562\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.8784 - f1_m: 0.8773 - precision_m: 0.9112 - recall_m: 0.8466 \n",
      "Epoch 00005: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0005--0.2347--0.7500.h5\n",
      "58/58 [==============================] - 3638s 63s/step - loss: 0.1538 - accuracy: 0.8784 - f1_m: 0.8773 - precision_m: 0.9112 - recall_m: 0.8466 - val_loss: 0.2347 - val_accuracy: 0.7500 - val_f1_m: 0.7586 - val_precision_m: 0.8462 - val_recall_m: 0.6875\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9146 - f1_m: 0.9144 - precision_m: 0.9379 - recall_m: 0.8927 \n",
      "Epoch 00006: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0006--0.2426--0.7812.h5\n",
      "58/58 [==============================] - 3768s 65s/step - loss: 0.1174 - accuracy: 0.9146 - f1_m: 0.9144 - precision_m: 0.9379 - recall_m: 0.8927 - val_loss: 0.2426 - val_accuracy: 0.7812 - val_f1_m: 0.7869 - val_precision_m: 0.8276 - val_recall_m: 0.7500\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9319 - f1_m: 0.9335 - precision_m: 0.9494 - recall_m: 0.9186 \n",
      "Epoch 00007: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0007--0.2059--0.8438.h5\n",
      "58/58 [==============================] - 1809s 31s/step - loss: 0.0979 - accuracy: 0.9319 - f1_m: 0.9335 - precision_m: 0.9494 - recall_m: 0.9186 - val_loss: 0.2059 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9530 - f1_m: 0.9516 - precision_m: 0.9639 - recall_m: 0.9401 \n",
      "Epoch 00008: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0008--0.2007--0.8438.h5\n",
      "58/58 [==============================] - 1845s 32s/step - loss: 0.0765 - accuracy: 0.9530 - f1_m: 0.9516 - precision_m: 0.9639 - recall_m: 0.9401 - val_loss: 0.2007 - val_accuracy: 0.8438 - val_f1_m: 0.8000 - val_precision_m: 0.8571 - val_recall_m: 0.7500\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9605 - f1_m: 0.9565 - precision_m: 0.9668 - recall_m: 0.9467 \n",
      "Epoch 00009: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0009--0.2126--0.8125.h5\n",
      "58/58 [==============================] - 1847s 32s/step - loss: 0.0663 - accuracy: 0.9605 - f1_m: 0.9565 - precision_m: 0.9668 - recall_m: 0.9467 - val_loss: 0.2126 - val_accuracy: 0.8125 - val_f1_m: 0.7797 - val_precision_m: 0.8519 - val_recall_m: 0.7188\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9795 - f1_m: 0.9792 - precision_m: 0.9841 - recall_m: 0.9746 \n",
      "Epoch 00010: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0010--0.1949--0.7812.h5\n",
      "58/58 [==============================] - 1843s 32s/step - loss: 0.0469 - accuracy: 0.9795 - f1_m: 0.9792 - precision_m: 0.9841 - recall_m: 0.9746 - val_loss: 0.1949 - val_accuracy: 0.7812 - val_f1_m: 0.8000 - val_precision_m: 0.8571 - val_recall_m: 0.7500\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9778 - f1_m: 0.9780 - precision_m: 0.9837 - recall_m: 0.9725 \n",
      "Epoch 00011: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0011--0.1711--0.8438.h5\n",
      "58/58 [==============================] - 1829s 32s/step - loss: 0.0408 - accuracy: 0.9778 - f1_m: 0.9780 - precision_m: 0.9837 - recall_m: 0.9725 - val_loss: 0.1711 - val_accuracy: 0.8438 - val_f1_m: 0.8387 - val_precision_m: 0.8667 - val_recall_m: 0.8125\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9838 - f1_m: 0.9823 - precision_m: 0.9883 - recall_m: 0.9766 \n",
      "Epoch 00012: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0012--0.1193--0.8750.h5\n",
      "58/58 [==============================] - 1844s 32s/step - loss: 0.0349 - accuracy: 0.9838 - f1_m: 0.9823 - precision_m: 0.9883 - recall_m: 0.9766 - val_loss: 0.1193 - val_accuracy: 0.8750 - val_f1_m: 0.8710 - val_precision_m: 0.9000 - val_recall_m: 0.8438\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9870 - f1_m: 0.9864 - precision_m: 0.9891 - recall_m: 0.9838 \n",
      "Epoch 00013: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0013--0.1664--0.8125.h5\n",
      "58/58 [==============================] - 1815s 31s/step - loss: 0.0320 - accuracy: 0.9870 - f1_m: 0.9864 - precision_m: 0.9891 - recall_m: 0.9838 - val_loss: 0.1664 - val_accuracy: 0.8125 - val_f1_m: 0.8254 - val_precision_m: 0.8387 - val_recall_m: 0.8125\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9903 - f1_m: 0.9903 - precision_m: 0.9924 - recall_m: 0.9881 \n",
      "Epoch 00014: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0014--0.1662--0.8438.h5\n",
      "58/58 [==============================] - 1822s 31s/step - loss: 0.0258 - accuracy: 0.9903 - f1_m: 0.9903 - precision_m: 0.9924 - recall_m: 0.9881 - val_loss: 0.1662 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9849 - f1_m: 0.9851 - precision_m: 0.9881 - recall_m: 0.9822 \n",
      "Epoch 00015: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0015--0.1678--0.8750.h5\n",
      "58/58 [==============================] - 1826s 31s/step - loss: 0.0308 - accuracy: 0.9849 - f1_m: 0.9851 - precision_m: 0.9881 - recall_m: 0.9822 - val_loss: 0.1678 - val_accuracy: 0.8750 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9903 - f1_m: 0.9911 - precision_m: 0.9930 - recall_m: 0.9892 \n",
      "Epoch 00016: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0016--0.1894--0.8438.h5\n",
      "58/58 [==============================] - 1821s 31s/step - loss: 0.0207 - accuracy: 0.9903 - f1_m: 0.9911 - precision_m: 0.9930 - recall_m: 0.9892 - val_loss: 0.1894 - val_accuracy: 0.8438 - val_f1_m: 0.8065 - val_precision_m: 0.8333 - val_recall_m: 0.7812\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9941 - f1_m: 0.9936 - precision_m: 0.9945 - recall_m: 0.9929 \n",
      "Epoch 00017: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0017--0.1079--0.9375.h5\n",
      "58/58 [==============================] - 1821s 31s/step - loss: 0.0178 - accuracy: 0.9941 - f1_m: 0.9936 - precision_m: 0.9945 - recall_m: 0.9929 - val_loss: 0.1079 - val_accuracy: 0.9375 - val_f1_m: 0.9032 - val_precision_m: 0.9333 - val_recall_m: 0.8750\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9908 - f1_m: 0.9896 - precision_m: 0.9929 - recall_m: 0.9865 \n",
      "Epoch 00018: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0018--0.1561--0.8750.h5\n",
      "58/58 [==============================] - 1814s 31s/step - loss: 0.0203 - accuracy: 0.9908 - f1_m: 0.9896 - precision_m: 0.9929 - recall_m: 0.9865 - val_loss: 0.1561 - val_accuracy: 0.8750 - val_f1_m: 0.8387 - val_precision_m: 0.8667 - val_recall_m: 0.8125\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9886 - f1_m: 0.9881 - precision_m: 0.9897 - recall_m: 0.9865 \n",
      "Epoch 00019: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0019--0.1762--0.8125.h5\n",
      "58/58 [==============================] - 1828s 32s/step - loss: 0.0210 - accuracy: 0.9886 - f1_m: 0.9881 - precision_m: 0.9897 - recall_m: 0.9865 - val_loss: 0.1762 - val_accuracy: 0.8125 - val_f1_m: 0.8065 - val_precision_m: 0.8333 - val_recall_m: 0.7812\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9935 - f1_m: 0.9935 - precision_m: 0.9946 - recall_m: 0.9925 \n",
      "Epoch 00020: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0020--0.1634--0.8438.h5\n",
      "58/58 [==============================] - 1821s 31s/step - loss: 0.0156 - accuracy: 0.9935 - f1_m: 0.9935 - precision_m: 0.9946 - recall_m: 0.9925 - val_loss: 0.1634 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9903 - f1_m: 0.9894 - precision_m: 0.9913 - recall_m: 0.9876 \n",
      "Epoch 00021: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0021--0.1641--0.8750.h5\n",
      "58/58 [==============================] - 1825s 31s/step - loss: 0.0184 - accuracy: 0.9903 - f1_m: 0.9894 - precision_m: 0.9913 - recall_m: 0.9876 - val_loss: 0.1641 - val_accuracy: 0.8750 - val_f1_m: 0.8710 - val_precision_m: 0.9000 - val_recall_m: 0.8438\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9962 - f1_m: 0.9962 - precision_m: 0.9968 - recall_m: 0.9957 \n",
      "Epoch 00022: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0022--0.1719--0.8125.h5\n",
      "58/58 [==============================] - 1820s 31s/step - loss: 0.0128 - accuracy: 0.9962 - f1_m: 0.9962 - precision_m: 0.9968 - recall_m: 0.9957 - val_loss: 0.1719 - val_accuracy: 0.8125 - val_f1_m: 0.8254 - val_precision_m: 0.8387 - val_recall_m: 0.8125\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9978 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978 \n",
      "Epoch 00023: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0023--0.1619--0.8438.h5\n",
      "58/58 [==============================] - 1820s 31s/step - loss: 0.0107 - accuracy: 0.9978 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978 - val_loss: 0.1619 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9951 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 \n",
      "Epoch 00024: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0024--0.1386--0.8750.h5\n",
      "58/58 [==============================] - 1815s 31s/step - loss: 0.0136 - accuracy: 0.9951 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.1386 - val_accuracy: 0.8750 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9968 - f1_m: 0.9970 - precision_m: 0.9984 - recall_m: 0.9957 \n",
      "Epoch 00025: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0025--0.1206--0.8438.h5\n",
      "58/58 [==============================] - 1811s 31s/step - loss: 0.0106 - accuracy: 0.9968 - f1_m: 0.9970 - precision_m: 0.9984 - recall_m: 0.9957 - val_loss: 0.1206 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9978 - f1_m: 0.9974 - precision_m: 0.9983 - recall_m: 0.9966 \n",
      "Epoch 00026: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0026--0.1531--0.8438.h5\n",
      "58/58 [==============================] - 1824s 31s/step - loss: 0.0092 - accuracy: 0.9978 - f1_m: 0.9974 - precision_m: 0.9983 - recall_m: 0.9966 - val_loss: 0.1531 - val_accuracy: 0.8438 - val_f1_m: 0.8710 - val_precision_m: 0.9000 - val_recall_m: 0.8438\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9984 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978 \n",
      "Epoch 00027: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0027--0.1245--0.8438.h5\n",
      "58/58 [==============================] - 1829s 32s/step - loss: 0.0095 - accuracy: 0.9984 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978 - val_loss: 0.1245 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9968 - f1_m: 0.9970 - precision_m: 0.9973 - recall_m: 0.9968 \n",
      "Epoch 00028: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0028--0.1447--0.8750.h5\n",
      "58/58 [==============================] - 1833s 32s/step - loss: 0.0093 - accuracy: 0.9968 - f1_m: 0.9970 - precision_m: 0.9973 - recall_m: 0.9968 - val_loss: 0.1447 - val_accuracy: 0.8750 - val_f1_m: 0.8710 - val_precision_m: 0.9000 - val_recall_m: 0.8438\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9978 - f1_m: 0.9973 - precision_m: 0.9978 - recall_m: 0.9968 \n",
      "Epoch 00029: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0029--0.1723--0.8438.h5\n",
      "58/58 [==============================] - 1813s 31s/step - loss: 0.0091 - accuracy: 0.9978 - f1_m: 0.9973 - precision_m: 0.9978 - recall_m: 0.9968 - val_loss: 0.1723 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9968 - f1_m: 0.9965 - precision_m: 0.9968 - recall_m: 0.9962 \n",
      "Epoch 00030: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0030--0.1434--0.8438.h5\n",
      "58/58 [==============================] - 1817s 31s/step - loss: 0.0094 - accuracy: 0.9968 - f1_m: 0.9965 - precision_m: 0.9968 - recall_m: 0.9962 - val_loss: 0.1434 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9984 - f1_m: 0.9976 - precision_m: 0.9984 - recall_m: 0.9968 \n",
      "Epoch 00031: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0031--0.1343--0.8750.h5\n",
      "58/58 [==============================] - 1810s 31s/step - loss: 0.0073 - accuracy: 0.9984 - f1_m: 0.9976 - precision_m: 0.9984 - recall_m: 0.9968 - val_loss: 0.1343 - val_accuracy: 0.8750 - val_f1_m: 0.8889 - val_precision_m: 0.9032 - val_recall_m: 0.8750\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 \n",
      "Epoch 00032: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0032--0.1555--0.8750.h5\n",
      "58/58 [==============================] - 1812s 31s/step - loss: 0.0076 - accuracy: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.1555 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9978 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978 \n",
      "Epoch 00033: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0033--0.1858--0.8125.h5\n",
      "58/58 [==============================] - 1806s 31s/step - loss: 0.0072 - accuracy: 0.9978 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978 - val_loss: 0.1858 - val_accuracy: 0.8125 - val_f1_m: 0.8254 - val_precision_m: 0.8387 - val_recall_m: 0.8125\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9984 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 \n",
      "Epoch 00034: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0034--0.1085--0.8750.h5\n",
      "58/58 [==============================] - 1801s 31s/step - loss: 0.0063 - accuracy: 0.9984 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 - val_loss: 0.1085 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9973 - f1_m: 0.9973 - precision_m: 0.9973 - recall_m: 0.9973 \n",
      "Epoch 00035: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0035--0.1432--0.8750.h5\n",
      "58/58 [==============================] - 1840s 32s/step - loss: 0.0064 - accuracy: 0.9973 - f1_m: 0.9973 - precision_m: 0.9973 - recall_m: 0.9973 - val_loss: 0.1432 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 \n",
      "Epoch 00036: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0036--0.1802--0.8125.h5\n",
      "58/58 [==============================] - 1850s 32s/step - loss: 0.0068 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 - val_loss: 0.1802 - val_accuracy: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9968 - f1_m: 0.9964 - precision_m: 0.9972 - recall_m: 0.9956 \n",
      "Epoch 00037: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0037--0.1877--0.8125.h5\n",
      "58/58 [==============================] - 2115s 36s/step - loss: 0.0070 - accuracy: 0.9968 - f1_m: 0.9964 - precision_m: 0.9972 - recall_m: 0.9956 - val_loss: 0.1877 - val_accuracy: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9989 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 \n",
      "Epoch 00038: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0038--0.1722--0.8125.h5\n",
      "58/58 [==============================] - 1890s 33s/step - loss: 0.0066 - accuracy: 0.9989 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 - val_loss: 0.1722 - val_accuracy: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9957 - f1_m: 0.9962 - precision_m: 0.9967 - recall_m: 0.9957  \n",
      "Epoch 00039: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0039--0.1105--0.8750.h5\n",
      "58/58 [==============================] - 5111s 88s/step - loss: 0.0079 - accuracy: 0.9957 - f1_m: 0.9962 - precision_m: 0.9967 - recall_m: 0.9957 - val_loss: 0.1105 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 40/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9973 - f1_m: 0.9973 - precision_m: 0.9978 - recall_m: 0.9968  \n",
      "Epoch 00040: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0040--0.1665--0.8438.h5\n",
      "58/58 [==============================] - 4376s 75s/step - loss: 0.0073 - accuracy: 0.9973 - f1_m: 0.9973 - precision_m: 0.9978 - recall_m: 0.9968 - val_loss: 0.1665 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 41/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9984 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978  \n",
      "Epoch 00041: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0041--0.1211--0.8750.h5\n",
      "58/58 [==============================] - 4819s 83s/step - loss: 0.0056 - accuracy: 0.9984 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978 - val_loss: 0.1211 - val_accuracy: 0.8750 - val_f1_m: 0.8889 - val_precision_m: 0.9032 - val_recall_m: 0.8750\n",
      "Epoch 42/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9973 - f1_m: 0.9973 - precision_m: 0.9973 - recall_m: 0.9973  \n",
      "Epoch 00042: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0042--0.1148--0.9062.h5\n",
      "58/58 [==============================] - 4198s 72s/step - loss: 0.0058 - accuracy: 0.9973 - f1_m: 0.9973 - precision_m: 0.9973 - recall_m: 0.9973 - val_loss: 0.1148 - val_accuracy: 0.9062 - val_f1_m: 0.9062 - val_precision_m: 0.9062 - val_recall_m: 0.9062\n",
      "Epoch 43/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9978 - f1_m: 0.9978 - precision_m: 0.9978 - recall_m: 0.9978 \n",
      "Epoch 00043: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0043--0.1467--0.8438.h5\n",
      "58/58 [==============================] - 1899s 33s/step - loss: 0.0053 - accuracy: 0.9978 - f1_m: 0.9978 - precision_m: 0.9978 - recall_m: 0.9978 - val_loss: 0.1467 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 44/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00044: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0044--0.1726--0.8438.h5\n",
      "58/58 [==============================] - 1782s 31s/step - loss: 0.0038 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 45/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00045: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0045--0.1591--0.8438.h5\n",
      "58/58 [==============================] - 1816s 31s/step - loss: 0.0038 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.1591 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 46/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9978 - f1_m: 0.9976 - precision_m: 0.9978 - recall_m: 0.9973 \n",
      "Epoch 00046: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0046--0.1755--0.8438.h5\n",
      "58/58 [==============================] - 2390s 41s/step - loss: 0.0048 - accuracy: 0.9978 - f1_m: 0.9976 - precision_m: 0.9978 - recall_m: 0.9973 - val_loss: 0.1755 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 47/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00047: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0047--0.1677--0.8438.h5\n",
      "58/58 [==============================] - 1832s 32s/step - loss: 0.0040 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.1677 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 48/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9989 - f1_m: 0.9984 - precision_m: 0.9989 - recall_m: 0.9978 \n",
      "Epoch 00048: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0048--0.1320--0.8438.h5\n",
      "58/58 [==============================] - 1831s 32s/step - loss: 0.0042 - accuracy: 0.9989 - f1_m: 0.9984 - precision_m: 0.9989 - recall_m: 0.9978 - val_loss: 0.1320 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 49/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989 - f1_m: 0.9992 - precision_m: 0.9995 - recall_m: 0.9989 \n",
      "Epoch 00049: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0049--0.1681--0.8438.h5\n",
      "58/58 [==============================] - 1820s 31s/step - loss: 0.0036 - accuracy: 0.9989 - f1_m: 0.9992 - precision_m: 0.9995 - recall_m: 0.9989 - val_loss: 0.1681 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 50/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9995 - f1_m: 0.9993 - precision_m: 0.9993 - recall_m: 0.9993 \n",
      "Epoch 00050: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0050--0.1929--0.8125.h5\n",
      "58/58 [==============================] - 1827s 31s/step - loss: 0.0037 - accuracy: 0.9995 - f1_m: 0.9993 - precision_m: 0.9993 - recall_m: 0.9993 - val_loss: 0.1929 - val_accuracy: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
      "Epoch 51/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00051: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0051--0.1531--0.8750.h5\n",
      "58/58 [==============================] - 1822s 31s/step - loss: 0.0037 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1531 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00052: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0052--0.1519--0.8438.h5\n",
      "58/58 [==============================] - 1912s 33s/step - loss: 0.0035 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1519 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 53/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00053: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0053--0.1850--0.8125.h5\n",
      "58/58 [==============================] - 1820s 31s/step - loss: 0.0033 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 \n",
      "Epoch 00054: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0054--0.1105--0.9062.h5\n",
      "58/58 [==============================] - 1820s 31s/step - loss: 0.0045 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 - val_loss: 0.1105 - val_accuracy: 0.9062 - val_f1_m: 0.9062 - val_precision_m: 0.9062 - val_recall_m: 0.9062\n",
      "Epoch 55/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00055: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0055--0.1717--0.8438.h5\n",
      "58/58 [==============================] - 1820s 31s/step - loss: 0.0032 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1717 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 56/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00056: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0056--0.1356--0.8438.h5\n",
      "58/58 [==============================] - 1831s 32s/step - loss: 0.0035 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.1356 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 57/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00057: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0057--0.1960--0.8125.h5\n",
      "58/58 [==============================] - 1826s 31s/step - loss: 0.0027 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
      "Epoch 58/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00058: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0058--0.1800--0.8125.h5\n",
      "58/58 [==============================] - 1816s 31s/step - loss: 0.0028 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1800 - val_accuracy: 0.8125 - val_f1_m: 0.8254 - val_precision_m: 0.8387 - val_recall_m: 0.8125\n",
      "Epoch 59/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00059: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0059--0.1537--0.8438.h5\n",
      "58/58 [==============================] - 1867s 32s/step - loss: 0.0036 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.1537 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 60/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00060: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0060--0.0992--0.8750.h5\n",
      "58/58 [==============================] - 1592s 27s/step - loss: 0.0025 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 61/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9973 - f1_m: 0.9973 - precision_m: 0.9973 - recall_m: 0.9973 \n",
      "Epoch 00061: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0061--0.1517--0.8438.h5\n",
      "58/58 [==============================] - 997s 17s/step - loss: 0.0046 - accuracy: 0.9973 - f1_m: 0.9973 - precision_m: 0.9973 - recall_m: 0.9973 - val_loss: 0.1517 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 62/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9984 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 \n",
      "Epoch 00062: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0062--0.1344--0.8750.h5\n",
      "58/58 [==============================] - 968s 17s/step - loss: 0.0032 - accuracy: 0.9984 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 - val_loss: 0.1344 - val_accuracy: 0.8750 - val_f1_m: 0.8889 - val_precision_m: 0.9032 - val_recall_m: 0.8750\n",
      "Epoch 63/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9995 - f1_m: 0.9992 - precision_m: 0.9995 - recall_m: 0.9989 \n",
      "Epoch 00063: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0063--0.1824--0.8125.h5\n",
      "58/58 [==============================] - 968s 17s/step - loss: 0.0031 - accuracy: 0.9995 - f1_m: 0.9992 - precision_m: 0.9995 - recall_m: 0.9989 - val_loss: 0.1824 - val_accuracy: 0.8125 - val_f1_m: 0.8254 - val_precision_m: 0.8387 - val_recall_m: 0.8125\n",
      "Epoch 64/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00064: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0064--0.1787--0.8125.h5\n",
      "58/58 [==============================] - 966s 17s/step - loss: 0.0027 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1787 - val_accuracy: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
      "Epoch 65/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995 - f1_m: 0.9993 - precision_m: 0.9993 - recall_m: 0.9993 \n",
      "Epoch 00065: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0065--0.1202--0.8438.h5\n",
      "58/58 [==============================] - 970s 17s/step - loss: 0.0030 - accuracy: 0.9995 - f1_m: 0.9993 - precision_m: 0.9993 - recall_m: 0.9993 - val_loss: 0.1202 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 66/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00066: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0066--0.1588--0.8438.h5\n",
      "58/58 [==============================] - 969s 17s/step - loss: 0.0027 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1588 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 67/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9978 - f1_m: 0.9978 - precision_m: 0.9978 - recall_m: 0.9978 \n",
      "Epoch 00067: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0067--0.1317--0.8750.h5\n",
      "58/58 [==============================] - 966s 17s/step - loss: 0.0038 - accuracy: 0.9978 - f1_m: 0.9978 - precision_m: 0.9978 - recall_m: 0.9978 - val_loss: 0.1317 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 68/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 \n",
      "Epoch 00068: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0068--0.1573--0.8438.h5\n",
      "58/58 [==============================] - 968s 17s/step - loss: 0.0028 - accuracy: 1.0000 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 - val_loss: 0.1573 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 69/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00069: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0069--0.1216--0.8438.h5\n",
      "58/58 [==============================] - 965s 17s/step - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1216 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 70/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989 - f1_m: 0.9992 - precision_m: 0.9995 - recall_m: 0.9989 \n",
      "Epoch 00070: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0070--0.1288--0.8438.h5\n",
      "58/58 [==============================] - 968s 17s/step - loss: 0.0028 - accuracy: 0.9989 - f1_m: 0.9992 - precision_m: 0.9995 - recall_m: 0.9989 - val_loss: 0.1288 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 71/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00071: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0071--0.1623--0.8438.h5\n",
      "58/58 [==============================] - 975s 17s/step - loss: 0.0026 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1623 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 72/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00072: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0072--0.1397--0.8750.h5\n",
      "58/58 [==============================] - 972s 17s/step - loss: 0.0018 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 73/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00073: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0073--0.1122--0.8438.h5\n",
      "58/58 [==============================] - 969s 17s/step - loss: 0.0020 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 74/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 \n",
      "Epoch 00074: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0074--0.1707--0.8438.h5\n",
      "58/58 [==============================] - 968s 17s/step - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 - val_loss: 0.1707 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 75/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00075: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0075--0.1771--0.8438.h5\n",
      "58/58 [==============================] - 968s 17s/step - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1771 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 76/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00076: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0076--0.1754--0.8438.h5\n",
      "58/58 [==============================] - 970s 17s/step - loss: 0.0023 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 77/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00077: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0077--0.1704--0.8438.h5\n",
      "58/58 [==============================] - 969s 17s/step - loss: 0.0034 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1704 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 78/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9995 - f1_m: 0.9993 - precision_m: 0.9993 - recall_m: 0.9993 \n",
      "Epoch 00078: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0078--0.1276--0.8438.h5\n",
      "58/58 [==============================] - 969s 17s/step - loss: 0.0024 - accuracy: 0.9995 - f1_m: 0.9993 - precision_m: 0.9993 - recall_m: 0.9993 - val_loss: 0.1276 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 79/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 \n",
      "Epoch 00079: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0079--0.1940--0.8438.h5\n",
      "58/58 [==============================] - 968s 17s/step - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 - val_loss: 0.1940 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 80/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00080: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0080--0.1371--0.8438.h5\n",
      "58/58 [==============================] - 968s 17s/step - loss: 0.0017 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 81/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9978 - f1_m: 0.9978 - precision_m: 0.9978 - recall_m: 0.9978 \n",
      "Epoch 00081: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0081--0.1747--0.8438.h5\n",
      "58/58 [==============================] - 964s 17s/step - loss: 0.0034 - accuracy: 0.9978 - f1_m: 0.9978 - precision_m: 0.9978 - recall_m: 0.9978 - val_loss: 0.1747 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 82/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 \n",
      "Epoch 00082: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0082--0.1218--0.9062.h5\n",
      "58/58 [==============================] - 973s 17s/step - loss: 0.0029 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 - val_loss: 0.1218 - val_accuracy: 0.9062 - val_f1_m: 0.9206 - val_precision_m: 0.9355 - val_recall_m: 0.9062\n",
      "Epoch 83/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00083: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0083--0.1677--0.8438.h5\n",
      "58/58 [==============================] - 971s 17s/step - loss: 0.0016 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 84/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00084: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0084--0.1298--0.8438.h5\n",
      "58/58 [==============================] - 969s 17s/step - loss: 0.0015 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 85/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00085: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0085--0.1666--0.8438.h5\n",
      "58/58 [==============================] - 968s 17s/step - loss: 0.0021 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1666 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 86/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00086: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0086--0.1696--0.8438.h5\n",
      "58/58 [==============================] - 967s 17s/step - loss: 0.0017 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.8438 - val_f1_m: 0.8571 - val_precision_m: 0.8710 - val_recall_m: 0.8438\n",
      "Epoch 87/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00087: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0087--0.1688--0.8438.h5\n",
      "58/58 [==============================] - 967s 17s/step - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1688 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 88/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 \n",
      "Epoch 00088: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0088--0.1708--0.8438.h5\n",
      "58/58 [==============================] - 968s 17s/step - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 - val_loss: 0.1708 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 89/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00089: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0089--0.1160--0.8750.h5\n",
      "58/58 [==============================] - 968s 17s/step - loss: 0.0022 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 90/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00090: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0090--0.1968--0.8438.h5\n",
      "58/58 [==============================] - 970s 17s/step - loss: 0.0031 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1968 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 91/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00091: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0091--0.1576--0.8750.h5\n",
      "58/58 [==============================] - 969s 17s/step - loss: 0.0017 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 92/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00092: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0092--0.0944--0.9062.h5\n",
      "58/58 [==============================] - 968s 17s/step - loss: 0.0018 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9062 - val_f1_m: 0.9062 - val_precision_m: 0.9062 - val_recall_m: 0.9062\n",
      "Epoch 93/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 \n",
      "Epoch 00093: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0093--0.2098--0.8125.h5\n",
      "58/58 [==============================] - 1004s 17s/step - loss: 0.0018 - accuracy: 0.9995 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 - val_loss: 0.2098 - val_accuracy: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
      "Epoch 94/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00094: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0094--0.1505--0.8750.h5\n",
      "58/58 [==============================] - 1030s 18s/step - loss: 0.0016 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.1505 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 95/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00095: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0095--0.2050--0.8125.h5\n",
      "58/58 [==============================] - 1028s 18s/step - loss: 0.0015 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
      "Epoch 96/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00096: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0096--0.1086--0.8750.h5\n",
      "58/58 [==============================] - 1032s 18s/step - loss: 0.0016 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 97/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00097: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0097--0.1749--0.8438.h5\n",
      "58/58 [==============================] - 1011s 17s/step - loss: 0.0017 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
      "Epoch 98/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00098: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0098--0.1973--0.8125.h5\n",
      "58/58 [==============================] - 968s 17s/step - loss: 0.0016 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
      "Epoch 99/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00099: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0099--0.1906--0.8125.h5\n",
      "58/58 [==============================] - 967s 17s/step - loss: 0.0024 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.1906 - val_accuracy: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
      "Epoch 100/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00100: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\DenseNet169Weights\\model_weights.0100--0.0868--0.9062.h5\n",
      "58/58 [==============================] - 969s 17s/step - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.0868 - val_accuracy: 0.9062 - val_f1_m: 0.9062 - val_precision_m: 0.9062 - val_recall_m: 0.9062\n",
      "WARNING:tensorflow:From <ipython-input-7-31ca105ba1c7>:15: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "[0.199748694896698, 0.8125, 0.8124999403953552, 0.8125, 0.8125]\n",
      "WARNING:tensorflow:From <ipython-input-7-31ca105ba1c7>:25: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "40/40 [==============================] - 14s 349ms/step\n",
      "Confusion Matrix\n",
      "[[ 7  2  0  1]\n",
      " [ 2  6  1  1]\n",
      " [ 0  1  8  1]\n",
      " [ 0  0  0 10]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Bengin       0.78      0.70      0.74        10\n",
      "      InSitu       0.67      0.60      0.63        10\n",
      "    Invasive       0.89      0.80      0.84        10\n",
      "      Normal       0.77      1.00      0.87        10\n",
      "\n",
      "    accuracy                           0.78        40\n",
      "   macro avg       0.78      0.77      0.77        40\n",
      "weighted avg       0.78      0.78      0.77        40\n",
      "\n",
      "Accuracy: 0.775000\n",
      "Precision: 0.775000\n",
      "Recall: 0.775000\n",
      "F1 score: 0.775000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file saved_model already exists.\n",
      "Error occurred while processing: saved_model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sara\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\sara\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\100epochDenseNet169_my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit_generator(batch_size=train_generator.samples // batch_size, generator=train_generator, validation_data= validation_generator, validation_steps=validation_generator.samples // batch_size,epochs=25,callbacks= init_callbacks())\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=100,\n",
    "                    callbacks= init_callbacks()\n",
    ")\n",
    "\n",
    "\n",
    "vhistory=model.evaluate_generator(generator=valid_generator,\n",
    "steps=STEP_SIZE_VALID)\n",
    "\n",
    "print(vhistory)\n",
    "\n",
    "\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)\n",
    "\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Classification Report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, predicted_class_indices))\n",
    "print('Classification Report')\n",
    "target_names = ['Bengin', 'InSitu', 'Invasive','Normal']\n",
    "print(classification_report(test_generator.classes, predicted_class_indices, target_names=target_names))\n",
    "\n",
    "\n",
    "y_test = test_generator.classes[test_generator.index_array]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, predicted_class_indices)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test,predicted_class_indices,average='micro')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test,predicted_class_indices,average='micro')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test,predicted_class_indices,average='micro')\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "\n",
    "\n",
    "#ROC\n",
    "\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "# n_classes=4\n",
    "# for i in range(n_classes):\n",
    "#     fpr, tpr, _ = metrics.roc_curve(test_generator.classes, predicted_class_indices)\n",
    "\n",
    "#     roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "# colors = cycle(['blue', 'red', 'green','orange'])\n",
    "# for i, color in zip(range(n_classes), colors):\n",
    "#     plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "#              label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "#              ''.format(i, roc_auc[i]))\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "# plt.xlim([-0.05, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic for multi-class data')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"D:\\\\Graduation Project\\\\Dataset\\\\ICIAR2018_BACH_Challenge\\\\Dataset\\\\100epochDenseNet169results.csv\",index=False)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "!mkdir -p saved_model\n",
    "model.save('D:\\\\Graduation Project\\\\Dataset\\\\ICIAR2018_BACH_Challenge\\\\Dataset\\\\100epochDenseNet169_my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "trainModel_VGG16Aug.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
