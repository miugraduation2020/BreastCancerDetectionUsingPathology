{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tV019gBL8J4t",
    "outputId": "11feae0f-553b-4086-b9c3-54dc6fa24672"
   },
   "outputs": [],
   "source": [
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D1LQphux8J4x",
    "outputId": "f0f23e43-b52f-4e0a-c98d-adbfce9407a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1882 images belonging to 4 classes.\n",
      "Found 40 images belonging to 4 classes.\n",
      "Found 40 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "train_datagen = ImageDataGenerator() \n",
    "valid_datagen = ImageDataGenerator() \n",
    "test_datagen = ImageDataGenerator() \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=r\"D:\\\\Graduation Project\\\\Dataset\\\\ICIAR2018_BACH_Challenge\\\\Dataset\\\\AugPhotos\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory=r\"D:\\\\Graduation Project\\\\Dataset\\\\ICIAR2018_BACH_Challenge\\\\Dataset\\\\Validation\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=r\"D:\\\\Graduation Project\\\\Dataset\\\\ICIAR2018_BACH_Challenge\\\\Dataset\\\\Test\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Q6VzxVS8J40",
    "outputId": "cea9e807-c3d5-4ff1-c109-6b96de062cb8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "img_rows, img_cols, img_channel = 224, 224, 3\n",
    "base_model = tf.keras.applications.ResNet101(\n",
    "    include_top=False, weights='imagenet', input_tensor=None,\n",
    "    input_shape=(img_rows, img_cols, img_channel), pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "a1fPWtbEFEy0"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbE-uHbp8J41",
    "outputId": "9e7827d5-7d6e-484f-9660-37d497813124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 14, 14, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 14, 14, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 14, 14, 1024) 0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 14, 14, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 14, 14, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 14, 14, 1024) 0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 14, 14, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 14, 14, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 14, 14, 1024) 0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 14, 14, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 14, 14, 1024) 0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 14, 14, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 14, 14, 1024) 0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 14, 14, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 14, 14, 1024) 0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 14, 14, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 14, 14, 1024) 0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 14, 14, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 14, 14, 1024) 0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 14, 14, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 14, 14, 1024) 0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 14, 14, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 14, 14, 1024) 0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 14, 14, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 14, 14, 1024) 0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 14, 14, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 14, 14, 1024) 0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 14, 14, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 14, 14, 1024) 0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 14, 14, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 14, 14, 1024) 0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 14, 14, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 14, 14, 1024) 0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 14, 14, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 14, 14, 1024) 0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 14, 14, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 14, 14, 1024) 0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 4)            25691396    conv5_block3_out[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 68,349,572\n",
      "Trainable params: 68,244,228\n",
      "Non-trainable params: 105,344\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "add_model.add(Dense(256, activation='relu'))\n",
    "add_model.add(Dropout(0.5))\n",
    "\n",
    "add_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1Ypkputj8J42"
   },
   "outputs": [],
   "source": [
    "\n",
    "def init_callbacks():\n",
    "  from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "  base_path = \"D:\\\\Graduation Project\\\\Dataset\\\\ICIAR2018_BACH_Challenge\\\\Dataset\\\\ResNet101Weights\\\\\"\n",
    "\n",
    " \n",
    "  trained_models_path = base_path + 'model_weights'\n",
    "  model_names = trained_models_path + '.{epoch:04d}--{val_loss:.4f}--{val_accuracy:.4f}.h5'\n",
    "  model_checkpoint = ModelCheckpoint(model_names, monitor = 'val_accuracy', verbose=1,save_best_only=False,save_weights_only=True)\n",
    "\n",
    "  callbacks = [model_checkpoint]\n",
    "  return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PaX1kGKA8J44",
    "outputId": "d0e5edda-ac30-4aee-89c9-d1a2d342a185",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-cecda6e26f3c>:10: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7817 - accuracy: 0.4184 - f1_m: 0.4047 - precision_m: 0.4388 - recall_m: 0.3765 \n",
      "Epoch 00001: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0001--0.5246--0.5000.h5\n",
      "58/58 [==============================] - 1087s 19s/step - loss: 0.7817 - accuracy: 0.4184 - f1_m: 0.4047 - precision_m: 0.4388 - recall_m: 0.3765 - val_loss: 0.5246 - val_accuracy: 0.5000 - val_f1_m: 0.5091 - val_precision_m: 0.6087 - val_recall_m: 0.4375\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2980 - accuracy: 0.7286 - f1_m: 0.7215 - precision_m: 0.7674 - recall_m: 0.6824 \n",
      "Epoch 00002: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0002--0.4292--0.5625.h5\n",
      "58/58 [==============================] - 1070s 18s/step - loss: 0.2980 - accuracy: 0.7286 - f1_m: 0.7215 - precision_m: 0.7674 - recall_m: 0.6824 - val_loss: 0.4292 - val_accuracy: 0.5625 - val_f1_m: 0.5185 - val_precision_m: 0.6364 - val_recall_m: 0.4375\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.8551 - f1_m: 0.8498 - precision_m: 0.8827 - recall_m: 0.8201 \n",
      "Epoch 00003: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0003--0.3210--0.7188.h5\n",
      "58/58 [==============================] - 1069s 18s/step - loss: 0.1775 - accuracy: 0.8551 - f1_m: 0.8498 - precision_m: 0.8827 - recall_m: 0.8201 - val_loss: 0.3210 - val_accuracy: 0.7188 - val_f1_m: 0.6909 - val_precision_m: 0.8261 - val_recall_m: 0.5938\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 0.9086 - f1_m: 0.9084 - precision_m: 0.9310 - recall_m: 0.8877 \n",
      "Epoch 00004: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0004--0.2967--0.7500.h5\n",
      "58/58 [==============================] - 1070s 18s/step - loss: 0.1206 - accuracy: 0.9086 - f1_m: 0.9084 - precision_m: 0.9310 - recall_m: 0.8877 - val_loss: 0.2967 - val_accuracy: 0.7500 - val_f1_m: 0.7586 - val_precision_m: 0.8462 - val_recall_m: 0.6875\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9368 - f1_m: 0.9362 - precision_m: 0.9498 - recall_m: 0.9232 \n",
      "Epoch 00005: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0005--0.2835--0.7500.h5\n",
      "58/58 [==============================] - 1067s 18s/step - loss: 0.0923 - accuracy: 0.9368 - f1_m: 0.9362 - precision_m: 0.9498 - recall_m: 0.9232 - val_loss: 0.2835 - val_accuracy: 0.7500 - val_f1_m: 0.8136 - val_precision_m: 0.8889 - val_recall_m: 0.7500\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9438 - f1_m: 0.9461 - precision_m: 0.9535 - recall_m: 0.9391 \n",
      "Epoch 00006: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0006--0.3251--0.7188.h5\n",
      "58/58 [==============================] - 1065s 18s/step - loss: 0.0720 - accuracy: 0.9438 - f1_m: 0.9461 - precision_m: 0.9535 - recall_m: 0.9391 - val_loss: 0.3251 - val_accuracy: 0.7188 - val_f1_m: 0.7797 - val_precision_m: 0.8519 - val_recall_m: 0.7188\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9665 - f1_m: 0.9662 - precision_m: 0.9737 - recall_m: 0.9591 \n",
      "Epoch 00007: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0007--0.3533--0.6875.h5\n",
      "58/58 [==============================] - 1066s 18s/step - loss: 0.0529 - accuracy: 0.9665 - f1_m: 0.9662 - precision_m: 0.9737 - recall_m: 0.9591 - val_loss: 0.3533 - val_accuracy: 0.6875 - val_f1_m: 0.7333 - val_precision_m: 0.7857 - val_recall_m: 0.6875\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9724 - f1_m: 0.9713 - precision_m: 0.9769 - recall_m: 0.9659 \n",
      "Epoch 00008: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0008--0.4351--0.6562.h5\n",
      "58/58 [==============================] - 1069s 18s/step - loss: 0.0456 - accuracy: 0.9724 - f1_m: 0.9713 - precision_m: 0.9769 - recall_m: 0.9659 - val_loss: 0.4351 - val_accuracy: 0.6562 - val_f1_m: 0.6333 - val_precision_m: 0.6786 - val_recall_m: 0.5938\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9703 - f1_m: 0.9721 - precision_m: 0.9764 - recall_m: 0.9680 \n",
      "Epoch 00009: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0009--0.3578--0.7500.h5\n",
      "58/58 [==============================] - 1069s 18s/step - loss: 0.0375 - accuracy: 0.9703 - f1_m: 0.9721 - precision_m: 0.9764 - recall_m: 0.9680 - val_loss: 0.3578 - val_accuracy: 0.7500 - val_f1_m: 0.7619 - val_precision_m: 0.7742 - val_recall_m: 0.7500\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9881 - f1_m: 0.9879 - precision_m: 0.9901 - recall_m: 0.9857 \n",
      "Epoch 00010: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0010--0.4260--0.6875.h5\n",
      "58/58 [==============================] - 1067s 18s/step - loss: 0.0248 - accuracy: 0.9881 - f1_m: 0.9879 - precision_m: 0.9901 - recall_m: 0.9857 - val_loss: 0.4260 - val_accuracy: 0.6875 - val_f1_m: 0.6774 - val_precision_m: 0.7000 - val_recall_m: 0.6562\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9816 - f1_m: 0.9808 - precision_m: 0.9838 - recall_m: 0.9779 \n",
      "Epoch 00011: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0011--0.3545--0.7188.h5\n",
      "58/58 [==============================] - 1070s 18s/step - loss: 0.0304 - accuracy: 0.9816 - f1_m: 0.9808 - precision_m: 0.9838 - recall_m: 0.9779 - val_loss: 0.3545 - val_accuracy: 0.7188 - val_f1_m: 0.7333 - val_precision_m: 0.7857 - val_recall_m: 0.6875\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9849 - f1_m: 0.9837 - precision_m: 0.9864 - recall_m: 0.9811 \n",
      "Epoch 00012: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0012--0.3704--0.7188.h5\n",
      "58/58 [==============================] - 1070s 18s/step - loss: 0.0279 - accuracy: 0.9849 - f1_m: 0.9837 - precision_m: 0.9864 - recall_m: 0.9811 - val_loss: 0.3704 - val_accuracy: 0.7188 - val_f1_m: 0.7302 - val_precision_m: 0.7419 - val_recall_m: 0.7188\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9903 - f1_m: 0.9900 - precision_m: 0.9908 - recall_m: 0.9892 \n",
      "Epoch 00013: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0013--0.3401--0.7500.h5\n",
      "58/58 [==============================] - 1071s 18s/step - loss: 0.0210 - accuracy: 0.9903 - f1_m: 0.9900 - precision_m: 0.9908 - recall_m: 0.9892 - val_loss: 0.3401 - val_accuracy: 0.7500 - val_f1_m: 0.7742 - val_precision_m: 0.8000 - val_recall_m: 0.7500\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9914 - f1_m: 0.9914 - precision_m: 0.9919 - recall_m: 0.9908 \n",
      "Epoch 00014: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0014--0.3524--0.7500.h5\n",
      "58/58 [==============================] - 1074s 19s/step - loss: 0.0197 - accuracy: 0.9914 - f1_m: 0.9914 - precision_m: 0.9919 - recall_m: 0.9908 - val_loss: 0.3524 - val_accuracy: 0.7500 - val_f1_m: 0.7742 - val_precision_m: 0.8000 - val_recall_m: 0.7500\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9897 - f1_m: 0.9893 - precision_m: 0.9907 - recall_m: 0.9880 \n",
      "Epoch 00015: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0015--0.4317--0.7188.h5\n",
      "58/58 [==============================] - 1074s 19s/step - loss: 0.0185 - accuracy: 0.9897 - f1_m: 0.9893 - precision_m: 0.9907 - recall_m: 0.9880 - val_loss: 0.4317 - val_accuracy: 0.7188 - val_f1_m: 0.6984 - val_precision_m: 0.7097 - val_recall_m: 0.6875\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9919 - f1_m: 0.9922 - precision_m: 0.9935 - recall_m: 0.9908 \n",
      "Epoch 00016: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0016--0.3743--0.7500.h5\n",
      "58/58 [==============================] - 1070s 18s/step - loss: 0.0190 - accuracy: 0.9919 - f1_m: 0.9922 - precision_m: 0.9935 - recall_m: 0.9908 - val_loss: 0.3743 - val_accuracy: 0.7500 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9924 - f1_m: 0.9923 - precision_m: 0.9929 - recall_m: 0.9918 \n",
      "Epoch 00017: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0017--0.4188--0.6875.h5\n",
      "58/58 [==============================] - 1072s 18s/step - loss: 0.0159 - accuracy: 0.9924 - f1_m: 0.9923 - precision_m: 0.9929 - recall_m: 0.9918 - val_loss: 0.4188 - val_accuracy: 0.6875 - val_f1_m: 0.6774 - val_precision_m: 0.7000 - val_recall_m: 0.6562\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9957 - f1_m: 0.9954 - precision_m: 0.9962 - recall_m: 0.9946 \n",
      "Epoch 00018: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0018--0.2572--0.7500.h5\n",
      "58/58 [==============================] - 1066s 18s/step - loss: 0.0128 - accuracy: 0.9957 - f1_m: 0.9954 - precision_m: 0.9962 - recall_m: 0.9946 - val_loss: 0.2572 - val_accuracy: 0.7500 - val_f1_m: 0.7541 - val_precision_m: 0.7931 - val_recall_m: 0.7188\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9941 - f1_m: 0.9941 - precision_m: 0.9946 - recall_m: 0.9935 \n",
      "Epoch 00019: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0019--0.3678--0.7188.h5\n",
      "58/58 [==============================] - 1067s 18s/step - loss: 0.0146 - accuracy: 0.9941 - f1_m: 0.9941 - precision_m: 0.9946 - recall_m: 0.9935 - val_loss: 0.3678 - val_accuracy: 0.7188 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9946 - f1_m: 0.9943 - precision_m: 0.9946 - recall_m: 0.9941 \n",
      "Epoch 00020: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0020--0.3501--0.7500.h5\n",
      "58/58 [==============================] - 1065s 18s/step - loss: 0.0099 - accuracy: 0.9946 - f1_m: 0.9943 - precision_m: 0.9946 - recall_m: 0.9941 - val_loss: 0.3501 - val_accuracy: 0.7500 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9919 - f1_m: 0.9919 - precision_m: 0.9919 - recall_m: 0.9919 \n",
      "Epoch 00021: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0021--0.3478--0.7812.h5\n",
      "58/58 [==============================] - 1062s 18s/step - loss: 0.0137 - accuracy: 0.9919 - f1_m: 0.9919 - precision_m: 0.9919 - recall_m: 0.9919 - val_loss: 0.3478 - val_accuracy: 0.7812 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9951 - f1_m: 0.9949 - precision_m: 0.9952 - recall_m: 0.9946 \n",
      "Epoch 00022: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0022--0.2675--0.7812.h5\n",
      "58/58 [==============================] - 1067s 18s/step - loss: 0.0098 - accuracy: 0.9951 - f1_m: 0.9949 - precision_m: 0.9952 - recall_m: 0.9946 - val_loss: 0.2675 - val_accuracy: 0.7812 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9973 - f1_m: 0.9970 - precision_m: 0.9973 - recall_m: 0.9968 \n",
      "Epoch 00023: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0023--0.3790--0.7500.h5\n",
      "58/58 [==============================] - 1065s 18s/step - loss: 0.0084 - accuracy: 0.9973 - f1_m: 0.9970 - precision_m: 0.9973 - recall_m: 0.9968 - val_loss: 0.3790 - val_accuracy: 0.7500 - val_f1_m: 0.7619 - val_precision_m: 0.7742 - val_recall_m: 0.7500\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9968 - f1_m: 0.9961 - precision_m: 0.9967 - recall_m: 0.9956 \n",
      "Epoch 00024: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0024--0.4254--0.6875.h5\n",
      "58/58 [==============================] - 1066s 18s/step - loss: 0.0096 - accuracy: 0.9968 - f1_m: 0.9961 - precision_m: 0.9967 - recall_m: 0.9956 - val_loss: 0.4254 - val_accuracy: 0.6875 - val_f1_m: 0.7097 - val_precision_m: 0.7333 - val_recall_m: 0.6875\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9968 - f1_m: 0.9965 - precision_m: 0.9968 - recall_m: 0.9962 \n",
      "Epoch 00025: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0025--0.2427--0.7812.h5\n",
      "58/58 [==============================] - 1068s 18s/step - loss: 0.0086 - accuracy: 0.9968 - f1_m: 0.9965 - precision_m: 0.9968 - recall_m: 0.9962 - val_loss: 0.2427 - val_accuracy: 0.7812 - val_f1_m: 0.7937 - val_precision_m: 0.8065 - val_recall_m: 0.7812\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 \n",
      "Epoch 00026: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0026--0.3562--0.7812.h5\n",
      "58/58 [==============================] - 1065s 18s/step - loss: 0.0099 - accuracy: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.3562 - val_accuracy: 0.7812 - val_f1_m: 0.7812 - val_precision_m: 0.7812 - val_recall_m: 0.7812\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9968 - f1_m: 0.9970 - precision_m: 0.9973 - recall_m: 0.9968 \n",
      "Epoch 00027: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0027--0.4019--0.7188.h5\n",
      "58/58 [==============================] - 1058s 18s/step - loss: 0.0074 - accuracy: 0.9968 - f1_m: 0.9970 - precision_m: 0.9973 - recall_m: 0.9968 - val_loss: 0.4019 - val_accuracy: 0.7188 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 \n",
      "Epoch 00028: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0028--0.3719--0.7500.h5\n",
      "58/58 [==============================] - 1061s 18s/step - loss: 0.0065 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 - val_loss: 0.3719 - val_accuracy: 0.7500 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9951 - f1_m: 0.9949 - precision_m: 0.9952 - recall_m: 0.9946 \n",
      "Epoch 00029: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0029--0.3914--0.7500.h5\n",
      "58/58 [==============================] - 1060s 18s/step - loss: 0.0093 - accuracy: 0.9951 - f1_m: 0.9949 - precision_m: 0.9952 - recall_m: 0.9946 - val_loss: 0.3914 - val_accuracy: 0.7500 - val_f1_m: 0.7619 - val_precision_m: 0.7742 - val_recall_m: 0.7500\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9968 - f1_m: 0.9973 - precision_m: 0.9978 - recall_m: 0.9968 \n",
      "Epoch 00030: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0030--0.2005--0.8438.h5\n",
      "58/58 [==============================] - 1061s 18s/step - loss: 0.0060 - accuracy: 0.9968 - f1_m: 0.9973 - precision_m: 0.9978 - recall_m: 0.9968 - val_loss: 0.2005 - val_accuracy: 0.8438 - val_f1_m: 0.8254 - val_precision_m: 0.8387 - val_recall_m: 0.8125\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9995 - recall_m: 0.9984 \n",
      "Epoch 00031: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0031--0.3584--0.7500.h5\n",
      "58/58 [==============================] - 1058s 18s/step - loss: 0.0055 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9995 - recall_m: 0.9984 - val_loss: 0.3584 - val_accuracy: 0.7500 - val_f1_m: 0.7619 - val_precision_m: 0.7742 - val_recall_m: 0.7500\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9984 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978 \n",
      "Epoch 00032: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0032--0.3718--0.7500.h5\n",
      "58/58 [==============================] - 1061s 18s/step - loss: 0.0054 - accuracy: 0.9984 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978 - val_loss: 0.3718 - val_accuracy: 0.7500 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978 \n",
      "Epoch 00033: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0033--0.2625--0.8438.h5\n",
      "58/58 [==============================] - 1062s 18s/step - loss: 0.0060 - accuracy: 0.9984 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978 - val_loss: 0.2625 - val_accuracy: 0.8438 - val_f1_m: 0.8525 - val_precision_m: 0.8966 - val_recall_m: 0.8125\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9968 - f1_m: 0.9966 - precision_m: 0.9966 - recall_m: 0.9966 \n",
      "Epoch 00034: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0034--0.3799--0.7188.h5\n",
      "58/58 [==============================] - 1060s 18s/step - loss: 0.0062 - accuracy: 0.9968 - f1_m: 0.9966 - precision_m: 0.9966 - recall_m: 0.9966 - val_loss: 0.3799 - val_accuracy: 0.7188 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9962 - f1_m: 0.9962 - precision_m: 0.9968 - recall_m: 0.9957 \n",
      "Epoch 00035: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0035--0.3667--0.7500.h5\n",
      "58/58 [==============================] - 1057s 18s/step - loss: 0.0067 - accuracy: 0.9962 - f1_m: 0.9962 - precision_m: 0.9968 - recall_m: 0.9957 - val_loss: 0.3667 - val_accuracy: 0.7500 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 \n",
      "Epoch 00036: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0036--0.3968--0.7188.h5\n",
      "58/58 [==============================] - 1077s 19s/step - loss: 0.0046 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 - val_loss: 0.3968 - val_accuracy: 0.7188 - val_f1_m: 0.7213 - val_precision_m: 0.7586 - val_recall_m: 0.6875\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9978 - f1_m: 0.9976 - precision_m: 0.9978 - recall_m: 0.9973 \n",
      "Epoch 00037: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0037--0.4035--0.7500.h5\n",
      "58/58 [==============================] - 1171s 20s/step - loss: 0.0062 - accuracy: 0.9978 - f1_m: 0.9976 - precision_m: 0.9978 - recall_m: 0.9973 - val_loss: 0.4035 - val_accuracy: 0.7500 - val_f1_m: 0.7213 - val_precision_m: 0.7586 - val_recall_m: 0.6875\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 \n",
      "Epoch 00038: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0038--0.3500--0.7812.h5\n",
      "58/58 [==============================] - 1102s 19s/step - loss: 0.0055 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 - val_loss: 0.3500 - val_accuracy: 0.7812 - val_f1_m: 0.7869 - val_precision_m: 0.8276 - val_recall_m: 0.7500\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 \n",
      "Epoch 00039: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0039--0.2383--0.7812.h5\n",
      "58/58 [==============================] - 1059s 18s/step - loss: 0.0030 - accuracy: 1.0000 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 - val_loss: 0.2383 - val_accuracy: 0.7812 - val_f1_m: 0.7742 - val_precision_m: 0.8000 - val_recall_m: 0.7500\n",
      "Epoch 40/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9978 - f1_m: 0.9978 - precision_m: 0.9978 - recall_m: 0.9978 \n",
      "Epoch 00040: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0040--0.2196--0.7812.h5\n",
      "58/58 [==============================] - 1060s 18s/step - loss: 0.0046 - accuracy: 0.9978 - f1_m: 0.9978 - precision_m: 0.9978 - recall_m: 0.9978 - val_loss: 0.2196 - val_accuracy: 0.7812 - val_f1_m: 0.7797 - val_precision_m: 0.8519 - val_recall_m: 0.7188\n",
      "Epoch 41/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9962 - f1_m: 0.9968 - precision_m: 0.9973 - recall_m: 0.9962 \n",
      "Epoch 00041: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0041--0.3824--0.7188.h5\n",
      "58/58 [==============================] - 1058s 18s/step - loss: 0.0055 - accuracy: 0.9962 - f1_m: 0.9968 - precision_m: 0.9973 - recall_m: 0.9962 - val_loss: 0.3824 - val_accuracy: 0.7188 - val_f1_m: 0.7302 - val_precision_m: 0.7419 - val_recall_m: 0.7188\n",
      "Epoch 42/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9973 - f1_m: 0.9976 - precision_m: 0.9978 - recall_m: 0.9973 \n",
      "Epoch 00042: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0042--0.2707--0.7500.h5\n",
      "58/58 [==============================] - 1061s 18s/step - loss: 0.0055 - accuracy: 0.9973 - f1_m: 0.9976 - precision_m: 0.9978 - recall_m: 0.9973 - val_loss: 0.2707 - val_accuracy: 0.7500 - val_f1_m: 0.7333 - val_precision_m: 0.7857 - val_recall_m: 0.6875\n",
      "Epoch 43/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00043: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0043--0.2769--0.7500.h5\n",
      "58/58 [==============================] - 1062s 18s/step - loss: 0.0034 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.2769 - val_accuracy: 0.7500 - val_f1_m: 0.7541 - val_precision_m: 0.7931 - val_recall_m: 0.7188\n",
      "Epoch 44/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00044: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0044--0.3961--0.6875.h5\n",
      "58/58 [==============================] - 1622s 28s/step - loss: 0.0037 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.6875 - val_f1_m: 0.6984 - val_precision_m: 0.7097 - val_recall_m: 0.6875\n",
      "Epoch 45/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00045: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0045--0.2927--0.7500.h5\n",
      "58/58 [==============================] - 1902s 33s/step - loss: 0.0036 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.2927 - val_accuracy: 0.7500 - val_f1_m: 0.7302 - val_precision_m: 0.7419 - val_recall_m: 0.7188\n",
      "Epoch 46/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00046: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0046--0.4012--0.7500.h5\n",
      "58/58 [==============================] - 1906s 33s/step - loss: 0.0042 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.4012 - val_accuracy: 0.7500 - val_f1_m: 0.7213 - val_precision_m: 0.7586 - val_recall_m: 0.6875\n",
      "Epoch 47/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 \n",
      "Epoch 00047: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0047--0.4086--0.7188.h5\n",
      "58/58 [==============================] - 2219s 38s/step - loss: 0.0034 - accuracy: 0.9989 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 - val_loss: 0.4086 - val_accuracy: 0.7188 - val_f1_m: 0.7302 - val_precision_m: 0.7419 - val_recall_m: 0.7188\n",
      "Epoch 48/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9989 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 \n",
      "Epoch 00048: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0048--0.4453--0.6562.h5\n",
      "58/58 [==============================] - 2412s 42s/step - loss: 0.0037 - accuracy: 0.9989 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 - val_loss: 0.4453 - val_accuracy: 0.6562 - val_f1_m: 0.6667 - val_precision_m: 0.6774 - val_recall_m: 0.6562\n",
      "Epoch 49/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00049: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0049--0.3806--0.6875.h5\n",
      "58/58 [==============================] - 5095s 88s/step - loss: 0.0030 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.3806 - val_accuracy: 0.6875 - val_f1_m: 0.7213 - val_precision_m: 0.7586 - val_recall_m: 0.6875\n",
      "Epoch 50/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9978 - f1_m: 0.9978 - precision_m: 0.9978 - recall_m: 0.9978 \n",
      "Epoch 00050: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0050--0.3139--0.7812.h5\n",
      "58/58 [==============================] - 2311s 40s/step - loss: 0.0033 - accuracy: 0.9978 - f1_m: 0.9978 - precision_m: 0.9978 - recall_m: 0.9978 - val_loss: 0.3139 - val_accuracy: 0.7812 - val_f1_m: 0.8065 - val_precision_m: 0.8333 - val_recall_m: 0.7812\n",
      "Epoch 51/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00051: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0051--0.4232--0.6875.h5\n",
      "58/58 [==============================] - 1899s 33s/step - loss: 0.0039 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.4232 - val_accuracy: 0.6875 - val_f1_m: 0.7097 - val_precision_m: 0.7333 - val_recall_m: 0.6875\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 \n",
      "Epoch 00052: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0052--0.2268--0.8125.h5\n",
      "58/58 [==============================] - 1890s 33s/step - loss: 0.0034 - accuracy: 0.9989 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 - val_loss: 0.2268 - val_accuracy: 0.8125 - val_f1_m: 0.7937 - val_precision_m: 0.8065 - val_recall_m: 0.7812\n",
      "Epoch 53/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00053: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0053--0.3787--0.7188.h5\n",
      "58/58 [==============================] - 1898s 33s/step - loss: 0.0026 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.3787 - val_accuracy: 0.7188 - val_f1_m: 0.7302 - val_precision_m: 0.7419 - val_recall_m: 0.7188\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9995 - recall_m: 0.9984 \n",
      "Epoch 00054: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0054--0.2568--0.7500.h5\n",
      "58/58 [==============================] - 1874s 32s/step - loss: 0.0031 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9995 - recall_m: 0.9984 - val_loss: 0.2568 - val_accuracy: 0.7500 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 55/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00055: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0055--0.3764--0.7812.h5\n",
      "58/58 [==============================] - 1910s 33s/step - loss: 0.0027 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.3764 - val_accuracy: 0.7812 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 56/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00056: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0056--0.3918--0.7500.h5\n",
      "58/58 [==============================] - 1890s 33s/step - loss: 0.0027 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.3918 - val_accuracy: 0.7500 - val_f1_m: 0.7619 - val_precision_m: 0.7742 - val_recall_m: 0.7500\n",
      "Epoch 57/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9978 - f1_m: 0.9978 - precision_m: 0.9978 - recall_m: 0.9978 \n",
      "Epoch 00057: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0057--0.3550--0.7500.h5\n",
      "58/58 [==============================] - 1889s 33s/step - loss: 0.0035 - accuracy: 0.9978 - f1_m: 0.9978 - precision_m: 0.9978 - recall_m: 0.9978 - val_loss: 0.3550 - val_accuracy: 0.7500 - val_f1_m: 0.7869 - val_precision_m: 0.8276 - val_recall_m: 0.7500\n",
      "Epoch 58/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00058: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0058--0.3481--0.7500.h5\n",
      "58/58 [==============================] - 1889s 33s/step - loss: 0.0025 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.3481 - val_accuracy: 0.7500 - val_f1_m: 0.7742 - val_precision_m: 0.8000 - val_recall_m: 0.7500\n",
      "Epoch 59/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9984 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 \n",
      "Epoch 00059: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0059--0.4520--0.6562.h5\n",
      "58/58 [==============================] - 1882s 32s/step - loss: 0.0028 - accuracy: 0.9984 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 - val_loss: 0.4520 - val_accuracy: 0.6562 - val_f1_m: 0.6774 - val_precision_m: 0.7000 - val_recall_m: 0.6562\n",
      "Epoch 60/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00060: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0060--0.2976--0.7812.h5\n",
      "58/58 [==============================] - 1894s 33s/step - loss: 0.0024 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.2976 - val_accuracy: 0.7812 - val_f1_m: 0.8065 - val_precision_m: 0.8333 - val_recall_m: 0.7812\n",
      "Epoch 61/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00061: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0061--0.4160--0.7188.h5\n",
      "58/58 [==============================] - 1903s 33s/step - loss: 0.0022 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.4160 - val_accuracy: 0.7188 - val_f1_m: 0.7541 - val_precision_m: 0.7931 - val_recall_m: 0.7188\n",
      "Epoch 62/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 \n",
      "Epoch 00062: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0062--0.2208--0.7812.h5\n",
      "58/58 [==============================] - 1896s 33s/step - loss: 0.0028 - accuracy: 1.0000 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 - val_loss: 0.2208 - val_accuracy: 0.7812 - val_f1_m: 0.8065 - val_precision_m: 0.8333 - val_recall_m: 0.7812\n",
      "Epoch 63/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00063: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0063--0.4269--0.6875.h5\n",
      "58/58 [==============================] - 1894s 33s/step - loss: 0.0024 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.6875 - val_f1_m: 0.7097 - val_precision_m: 0.7333 - val_recall_m: 0.6875\n",
      "Epoch 64/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 \n",
      "Epoch 00064: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0064--0.3978--0.7188.h5\n",
      "58/58 [==============================] - 1892s 33s/step - loss: 0.0020 - accuracy: 1.0000 - f1_m: 0.9997 - precision_m: 1.0000 - recall_m: 0.9995 - val_loss: 0.3978 - val_accuracy: 0.7188 - val_f1_m: 0.7302 - val_precision_m: 0.7419 - val_recall_m: 0.7188\n",
      "Epoch 65/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00065: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0065--0.4351--0.6875.h5\n",
      "58/58 [==============================] - 1898s 33s/step - loss: 0.0023 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.4351 - val_accuracy: 0.6875 - val_f1_m: 0.6984 - val_precision_m: 0.7097 - val_recall_m: 0.6875\n",
      "Epoch 66/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9989 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 \n",
      "Epoch 00066: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0066--0.4039--0.6875.h5\n",
      "58/58 [==============================] - 1887s 33s/step - loss: 0.0024 - accuracy: 0.9989 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 - val_loss: 0.4039 - val_accuracy: 0.6875 - val_f1_m: 0.7097 - val_precision_m: 0.7333 - val_recall_m: 0.6875\n",
      "Epoch 67/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00067: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0067--0.2925--0.7500.h5\n",
      "58/58 [==============================] - 1889s 33s/step - loss: 0.0026 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.2925 - val_accuracy: 0.7500 - val_f1_m: 0.7619 - val_precision_m: 0.7742 - val_recall_m: 0.7500\n",
      "Epoch 68/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9995 - f1_m: 0.9993 - precision_m: 0.9993 - recall_m: 0.9993 \n",
      "Epoch 00068: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0068--0.4401--0.6875.h5\n",
      "58/58 [==============================] - 1896s 33s/step - loss: 0.0024 - accuracy: 0.9995 - f1_m: 0.9993 - precision_m: 0.9993 - recall_m: 0.9993 - val_loss: 0.4401 - val_accuracy: 0.6875 - val_f1_m: 0.7213 - val_precision_m: 0.7586 - val_recall_m: 0.6875\n",
      "Epoch 69/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 \n",
      "Epoch 00069: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0069--0.3983--0.7188.h5\n",
      "58/58 [==============================] - 1890s 33s/step - loss: 0.0036 - accuracy: 0.9989 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 - val_loss: 0.3983 - val_accuracy: 0.7188 - val_f1_m: 0.7213 - val_precision_m: 0.7586 - val_recall_m: 0.6875\n",
      "Epoch 70/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00070: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0070--0.4526--0.6562.h5\n",
      "58/58 [==============================] - 1901s 33s/step - loss: 0.0021 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.4526 - val_accuracy: 0.6562 - val_f1_m: 0.6667 - val_precision_m: 0.6774 - val_recall_m: 0.6562\n",
      "Epoch 71/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00071: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0071--0.3868--0.7500.h5\n",
      "58/58 [==============================] - 1898s 33s/step - loss: 0.0021 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.3868 - val_accuracy: 0.7500 - val_f1_m: 0.7619 - val_precision_m: 0.7742 - val_recall_m: 0.7500\n",
      "Epoch 72/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00072: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0072--0.2346--0.8125.h5\n",
      "58/58 [==============================] - 1888s 33s/step - loss: 0.0023 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.2346 - val_accuracy: 0.8125 - val_f1_m: 0.8065 - val_precision_m: 0.8333 - val_recall_m: 0.7812\n",
      "Epoch 73/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00073: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0073--0.3718--0.7500.h5\n",
      "58/58 [==============================] - 1904s 33s/step - loss: 0.0021 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.3718 - val_accuracy: 0.7500 - val_f1_m: 0.7742 - val_precision_m: 0.8000 - val_recall_m: 0.7500\n",
      "Epoch 74/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9991 - precision_m: 0.9993 - recall_m: 0.9988 \n",
      "Epoch 00074: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0074--0.3920--0.7188.h5\n",
      "58/58 [==============================] - 1895s 33s/step - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9991 - precision_m: 0.9993 - recall_m: 0.9988 - val_loss: 0.3920 - val_accuracy: 0.7188 - val_f1_m: 0.7667 - val_precision_m: 0.8214 - val_recall_m: 0.7188\n",
      "Epoch 75/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9989 - f1_m: 0.9992 - precision_m: 0.9995 - recall_m: 0.9989 \n",
      "Epoch 00075: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0075--0.4247--0.6562.h5\n",
      "58/58 [==============================] - 1883s 32s/step - loss: 0.0023 - accuracy: 0.9989 - f1_m: 0.9992 - precision_m: 0.9995 - recall_m: 0.9989 - val_loss: 0.4247 - val_accuracy: 0.6562 - val_f1_m: 0.7000 - val_precision_m: 0.7500 - val_recall_m: 0.6562\n",
      "Epoch 76/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00076: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0076--0.4070--0.7188.h5\n",
      "58/58 [==============================] - 1890s 33s/step - loss: 0.0020 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.7188 - val_f1_m: 0.7333 - val_precision_m: 0.7857 - val_recall_m: 0.6875\n",
      "Epoch 77/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00077: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0077--0.3172--0.6875.h5\n",
      "58/58 [==============================] - 1876s 32s/step - loss: 0.0021 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.3172 - val_accuracy: 0.6875 - val_f1_m: 0.7213 - val_precision_m: 0.7586 - val_recall_m: 0.6875\n",
      "Epoch 78/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00078: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0078--0.3856--0.7500.h5\n",
      "58/58 [==============================] - 2359s 41s/step - loss: 0.0015 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.7500 - val_f1_m: 0.7619 - val_precision_m: 0.7742 - val_recall_m: 0.7500\n",
      "Epoch 79/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00079: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0079--0.4053--0.7188.h5\n",
      "58/58 [==============================] - 2025s 35s/step - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.4053 - val_accuracy: 0.7188 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 80/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00080: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0080--0.3909--0.7188.h5\n",
      "58/58 [==============================] - 3643s 63s/step - loss: 0.0022 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.3909 - val_accuracy: 0.7188 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 81/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000  \n",
      "Epoch 00081: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0081--0.4061--0.7188.h5\n",
      "58/58 [==============================] - 4912s 85s/step - loss: 0.0013 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.7188 - val_f1_m: 0.7302 - val_precision_m: 0.7419 - val_recall_m: 0.7188\n",
      "Epoch 82/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00082: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0082--0.2683--0.7500.h5\n",
      "58/58 [==============================] - 4382s 76s/step - loss: 0.0028 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.2683 - val_accuracy: 0.7500 - val_f1_m: 0.7742 - val_precision_m: 0.8000 - val_recall_m: 0.7500\n",
      "Epoch 83/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989  \n",
      "Epoch 00083: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0083--0.3784--0.7188.h5\n",
      "58/58 [==============================] - 5189s 89s/step - loss: 0.0020 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.3784 - val_accuracy: 0.7188 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 84/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00084: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0084--0.4082--0.7188.h5\n",
      "58/58 [==============================] - 3197s 55s/step - loss: 0.0020 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.4082 - val_accuracy: 0.7188 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 85/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00085: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0085--0.3893--0.7188.h5\n",
      "58/58 [==============================] - 1981s 34s/step - loss: 0.0017 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.3893 - val_accuracy: 0.7188 - val_f1_m: 0.7541 - val_precision_m: 0.7931 - val_recall_m: 0.7188\n",
      "Epoch 86/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 \n",
      "Epoch 00086: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0086--0.4456--0.6875.h5\n",
      "58/58 [==============================] - 1982s 34s/step - loss: 0.0032 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 - val_loss: 0.4456 - val_accuracy: 0.6875 - val_f1_m: 0.7097 - val_precision_m: 0.7333 - val_recall_m: 0.6875\n",
      "Epoch 87/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9993 - precision_m: 0.9993 - recall_m: 0.9993 \n",
      "Epoch 00087: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0087--0.3493--0.7188.h5\n",
      "58/58 [==============================] - 2650s 46s/step - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9993 - precision_m: 0.9993 - recall_m: 0.9993 - val_loss: 0.3493 - val_accuracy: 0.7188 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 88/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 \n",
      "Epoch 00088: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0088--0.3161--0.7188.h5\n",
      "58/58 [==============================] - 1886s 33s/step - loss: 0.0026 - accuracy: 0.9984 - f1_m: 0.9984 - precision_m: 0.9984 - recall_m: 0.9984 - val_loss: 0.3161 - val_accuracy: 0.7188 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "Epoch 89/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9978 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978 \n",
      "Epoch 00089: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0089--0.4109--0.7500.h5\n",
      "58/58 [==============================] - 1891s 33s/step - loss: 0.0024 - accuracy: 0.9978 - f1_m: 0.9981 - precision_m: 0.9984 - recall_m: 0.9978 - val_loss: 0.4109 - val_accuracy: 0.7500 - val_f1_m: 0.7619 - val_precision_m: 0.7742 - val_recall_m: 0.7500\n",
      "Epoch 90/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9989 - f1_m: 0.9988 - precision_m: 0.9988 - recall_m: 0.9988 \n",
      "Epoch 00090: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0090--0.4316--0.6875.h5\n",
      "58/58 [==============================] - 1896s 33s/step - loss: 0.0027 - accuracy: 0.9989 - f1_m: 0.9988 - precision_m: 0.9988 - recall_m: 0.9988 - val_loss: 0.4316 - val_accuracy: 0.6875 - val_f1_m: 0.6984 - val_precision_m: 0.7097 - val_recall_m: 0.6875\n",
      "Epoch 91/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9984 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 \n",
      "Epoch 00091: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0091--0.3624--0.7500.h5\n",
      "58/58 [==============================] - 1894s 33s/step - loss: 0.0026 - accuracy: 0.9984 - f1_m: 0.9986 - precision_m: 0.9989 - recall_m: 0.9984 - val_loss: 0.3624 - val_accuracy: 0.7500 - val_f1_m: 0.7619 - val_precision_m: 0.7742 - val_recall_m: 0.7500\n",
      "Epoch 92/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00092: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0092--0.3378--0.8125.h5\n",
      "58/58 [==============================] - 1936s 33s/step - loss: 0.0016 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.3378 - val_accuracy: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
      "Epoch 93/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00093: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0093--0.4107--0.7188.h5\n",
      "58/58 [==============================] - 1930s 33s/step - loss: 0.0024 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.4107 - val_accuracy: 0.7188 - val_f1_m: 0.7302 - val_precision_m: 0.7419 - val_recall_m: 0.7188\n",
      "Epoch 94/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00094: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0094--0.2945--0.7188.h5\n",
      "58/58 [==============================] - 1893s 33s/step - loss: 0.0018 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.7188 - val_f1_m: 0.7302 - val_precision_m: 0.7419 - val_recall_m: 0.7188\n",
      "Epoch 95/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00095: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0095--0.4513--0.6562.h5\n",
      "58/58 [==============================] - 1887s 33s/step - loss: 0.0010 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.6562 - val_f1_m: 0.6774 - val_precision_m: 0.7000 - val_recall_m: 0.6562\n",
      "Epoch 96/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00096: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0096--0.3955--0.7500.h5\n",
      "58/58 [==============================] - 1889s 33s/step - loss: 0.0018 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.3955 - val_accuracy: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
      "Epoch 97/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 \n",
      "Epoch 00097: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0097--0.3690--0.7500.h5\n",
      "58/58 [==============================] - 1887s 33s/step - loss: 0.0016 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.3690 - val_accuracy: 0.7500 - val_f1_m: 0.7742 - val_precision_m: 0.8000 - val_recall_m: 0.7500\n",
      "Epoch 98/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 \n",
      "Epoch 00098: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0098--0.4229--0.6875.h5\n",
      "58/58 [==============================] - 1885s 32s/step - loss: 0.0020 - accuracy: 0.9989 - f1_m: 0.9989 - precision_m: 0.9989 - recall_m: 0.9989 - val_loss: 0.4229 - val_accuracy: 0.6875 - val_f1_m: 0.7097 - val_precision_m: 0.7333 - val_recall_m: 0.6875\n",
      "Epoch 99/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00099: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0099--0.3261--0.7812.h5\n",
      "58/58 [==============================] - 1884s 32s/step - loss: 0.0015 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.3261 - val_accuracy: 0.7812 - val_f1_m: 0.7742 - val_precision_m: 0.8000 - val_recall_m: 0.7500\n",
      "Epoch 100/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 \n",
      "Epoch 00100: saving model to D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\ResNet101Weights\\model_weights.0100--0.3797--0.7500.h5\n",
      "58/58 [==============================] - 2039s 35s/step - loss: 0.0014 - accuracy: 0.9995 - f1_m: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - val_loss: 0.3797 - val_accuracy: 0.7500 - val_f1_m: 0.7419 - val_precision_m: 0.7667 - val_recall_m: 0.7188\n",
      "WARNING:tensorflow:From <ipython-input-7-cecda6e26f3c>:15: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "[0.3724019527435303, 0.78125, 0.7741934657096863, 0.800000011920929, 0.75]\n",
      "WARNING:tensorflow:From <ipython-input-7-cecda6e26f3c>:25: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "40/40 [==============================] - 18s 452ms/step\n",
      "Confusion Matrix\n",
      "[[ 9  1  0  0]\n",
      " [ 0  8  0  2]\n",
      " [ 0  2  7  1]\n",
      " [ 0  0  0 10]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Bengin       1.00      0.90      0.95        10\n",
      "      InSitu       0.73      0.80      0.76        10\n",
      "    Invasive       1.00      0.70      0.82        10\n",
      "      Normal       0.77      1.00      0.87        10\n",
      "\n",
      "    accuracy                           0.85        40\n",
      "   macro avg       0.87      0.85      0.85        40\n",
      "weighted avg       0.87      0.85      0.85        40\n",
      "\n",
      "Accuracy: 0.850000\n",
      "Precision: 0.850000\n",
      "Recall: 0.850000\n",
      "F1 score: 0.850000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file saved_model already exists.\n",
      "Error occurred while processing: saved_model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sara\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\sara\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: D:\\Graduation Project\\Dataset\\ICIAR2018_BACH_Challenge\\Dataset\\100epochResNet101_my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit_generator(batch_size=train_generator.samples // batch_size, generator=train_generator, validation_data= validation_generator, validation_steps=validation_generator.samples // batch_size,epochs=25,callbacks= init_callbacks())\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=100,\n",
    "                    callbacks= init_callbacks()\n",
    ")\n",
    "\n",
    "\n",
    "vhistory=model.evaluate_generator(generator=valid_generator,\n",
    "steps=STEP_SIZE_VALID)\n",
    "\n",
    "print(vhistory)\n",
    "\n",
    "\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)\n",
    "\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Classification Report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, predicted_class_indices))\n",
    "print('Classification Report')\n",
    "target_names = ['Bengin', 'InSitu', 'Invasive','Normal']\n",
    "print(classification_report(test_generator.classes, predicted_class_indices, target_names=target_names))\n",
    "\n",
    "\n",
    "y_test = test_generator.classes[test_generator.index_array]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, predicted_class_indices)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test,predicted_class_indices,average='micro')\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test,predicted_class_indices,average='micro')\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test,predicted_class_indices,average='micro')\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "\n",
    "\n",
    "#ROC\n",
    "\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "# n_classes=4\n",
    "# for i in range(n_classes):\n",
    "#     fpr, tpr, _ = metrics.roc_curve(test_generator.classes, predicted_class_indices)\n",
    "\n",
    "#     roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "# colors = cycle(['blue', 'red', 'green','orange'])\n",
    "# for i, color in zip(range(n_classes), colors):\n",
    "#     plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "#              label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "#              ''.format(i, roc_auc[i]))\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "# plt.xlim([-0.05, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic for multi-class data')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"D:\\\\Graduation Project\\\\Dataset\\\\ICIAR2018_BACH_Challenge\\\\Dataset\\\\100epochResNet101results.csv\",index=False)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "!mkdir -p saved_model\n",
    "model.save('D:\\\\Graduation Project\\\\Dataset\\\\ICIAR2018_BACH_Challenge\\\\Dataset\\\\100epochResNet101_my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "trainModel_VGG16Aug.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
