{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tV019gBL8J4t",
    "outputId": "11feae0f-553b-4086-b9c3-54dc6fa24672"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\pc\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\pc\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\pc\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\pc\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\pc\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\pc\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import dill\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import scipy\n",
    "\n",
    "dill.dump_session('notebook_env2.db')\n",
    "dill.load_session('notebook_env.db')\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D1LQphux8J4x",
    "outputId": "f0f23e43-b52f-4e0a-c98d-adbfce9407a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "train_datagen = ImageDataGenerator() \n",
    "valid_datagen = ImageDataGenerator() \n",
    "test_datagen = ImageDataGenerator() \n",
    "\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=r\"D:/BACHDataset/SegTest\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Q6VzxVS8J40",
    "outputId": "cea9e807-c3d5-4ff1-c109-6b96de062cb8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "a1fPWtbEFEy0"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbE-uHbp8J41",
    "outputId": "9e7827d5-7d6e-484f-9660-37d497813124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pc\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\pc\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\pc\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\pc\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = []\n",
    "model1 = keras.models.load_model('D:\\\\BACHWeights\\\\DenseNetAugSeg\\\\my_model',custom_objects={'f1_m':f1_m,'precision_m':precision_m,'recall_m':recall_m})\n",
    "model2 = keras.models.load_model('D:\\\\BACHWeights\\ResNet50AugSeg\\\\my_model',custom_objects={'f1_m':f1_m,'precision_m':precision_m,'recall_m':recall_m})\n",
    "model3 = keras.models.load_model('D:\\\\BACHWeights\\ResNet101AugSeg\\\\my_model',custom_objects={'f1_m':f1_m,'precision_m':precision_m,'recall_m':recall_m})\n",
    "\n",
    "model.append(model1)\n",
    "model.append(model2)\n",
    "model.append(model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PaX1kGKA8J44",
    "outputId": "d0e5edda-ac30-4aee-89c9-d1a2d342a185",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 16s 392ms/step\n",
      "[0 0 0 1 0 0 3 2 0 0 1 1 0 1 1 1 1 1 1 1 3 2 2 2 2 2 0 2 2 2 3 3 1 3 3 3 3\n",
      " 3 3 3]\n",
      "Confusion Matrix\n",
      "[[7 1 1 1]\n",
      " [1 9 0 0]\n",
      " [1 0 8 1]\n",
      " [0 1 0 9]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Bengin       0.78      0.70      0.74        10\n",
      "      InSitu       0.82      0.90      0.86        10\n",
      "    Invasive       0.89      0.80      0.84        10\n",
      "      Normal       0.82      0.90      0.86        10\n",
      "\n",
      "    accuracy                           0.82        40\n",
      "   macro avg       0.83      0.83      0.82        40\n",
      "weighted avg       0.83      0.82      0.82        40\n",
      "\n",
      "40/40 [==============================] - 13s 337ms/step\n",
      "[0 1 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 2 2 1 2 3 2 2 2 2 3 3 3 3 3 3 3\n",
      " 3 3 3]\n",
      "Confusion Matrix\n",
      "[[ 8  2  0  0]\n",
      " [ 1  9  0  0]\n",
      " [ 1  1  7  1]\n",
      " [ 0  0  0 10]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Bengin       0.80      0.80      0.80        10\n",
      "      InSitu       0.75      0.90      0.82        10\n",
      "    Invasive       1.00      0.70      0.82        10\n",
      "      Normal       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.85        40\n",
      "   macro avg       0.86      0.85      0.85        40\n",
      "weighted avg       0.86      0.85      0.85        40\n",
      "\n",
      "40/40 [==============================] - 28s 710ms/step\n",
      "[3 0 0 1 0 0 0 2 0 0 1 1 1 1 3 1 1 1 1 1 3 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3\n",
      " 3 3 3]\n",
      "Confusion Matrix\n",
      "[[ 7  1  1  1]\n",
      " [ 0  9  0  1]\n",
      " [ 0  0  9  1]\n",
      " [ 0  0  0 10]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Bengin       1.00      0.70      0.82        10\n",
      "      InSitu       0.90      0.90      0.90        10\n",
      "    Invasive       0.90      0.90      0.90        10\n",
      "      Normal       0.77      1.00      0.87        10\n",
      "\n",
      "    accuracy                           0.88        40\n",
      "   macro avg       0.89      0.88      0.87        40\n",
      "weighted avg       0.89      0.88      0.87        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "models = []\n",
    "for i in range(len(model)):\n",
    "\n",
    "    models.append(model[i])\n",
    "\n",
    "\n",
    "\n",
    "# #Predictions\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "# Predict labels with models\n",
    "labels = []\n",
    "for m in models:\n",
    "    pred=m.predict_generator(test_generator,\n",
    "    steps=STEP_SIZE_TEST,\n",
    "    verbose=1)\n",
    "    predicts=np.argmax(pred,axis=-1)\n",
    "    labels.append(predicts)\n",
    "    #print(pred)\n",
    "\n",
    "    #Classification Report\n",
    "\n",
    "    print(predicts)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(test_generator.classes,predicts))\n",
    "    print('Classification Report')\n",
    "    target_names = ['Bengin', 'InSitu', 'Invasive','Normal']\n",
    "    print(classification_report(test_generator.classes, predicts, target_names=target_names))\n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Ensemble with voting\n",
    "labels = np.array(labels)\n",
    "labels = np.transpose(labels, (1, 0))\n",
    "labels = scipy.stats.mode(labels, axis=1)[0]\n",
    "labels = np.squeeze(labels)\n",
    "\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "pd.DataFrame({'ImageId' : filenames, 'Label' : labels }).to_csv(\"D:\\\\BACHWeights\\\\results.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "trainModel_VGG16Aug.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
